{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: LFW-People (https://www.kaggle.com/atulanandjha/lfwpeople/data)\n",
    "\n",
    "VGGFace2\n",
    "(https://machinelearningmastery.com/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../slnp_faces_leg_55\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dirs,_ = next(os.walk(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = pd.DataFrame(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders.columns = [\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105112_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112437_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113247_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114941_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118594_b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name\n",
       "0  105112_b\n",
       "1  112437_b\n",
       "2  113247_b\n",
       "3  114941_b\n",
       "4  118594_b"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picture Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders[\"file\"] = folders[\"name\"].apply(lambda x: [f for f in os.listdir(dataset_dir+\"/\"+x) if f.endswith(\".jpg\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name    514\n",
       "file    514\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures = pd.DataFrame(folders.file.tolist(), index=folders.name).stack().reset_index(level=1, drop=True).reset_index(name='file')[['file','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file    9138\n",
       "name    9138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pictures.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\n",
    "    pixels = cv2.imread(filename)\n",
    "    if pixels is not None:\n",
    "        pixels_rgb = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = detector.detect_faces(pixels_rgb)\n",
    "\n",
    "        if len(results)>0:\n",
    "\n",
    "            x1, y1, width, height = results[0]['box']\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            face = pixels_rgb[y1:y2, x1:x2]\n",
    "\n",
    "            if face.shape[0]>0 and face.shape[1]>0:\n",
    "                return cv2.resize(face, required_size)\n",
    "\n",
    "    return 'no_face'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone= 'senet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGFace(model=backbone, include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(filename):\n",
    "    face = extract_face(filename)\n",
    "    if face == 'no_face':\n",
    "        return '-'\n",
    "    sample = np.asarray(face, 'float32')\n",
    "    sample = np.expand_dims(sample, axis=0)\n",
    "    sample = preprocess_input(sample, version=2)\n",
    "    \n",
    "    embedding = model.predict(sample)\n",
    "    \n",
    "    return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_urls = dataset_dir+'/'+pictures['name']+'/'+pictures['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paulo\\.virtualenvs\\face_clustering-td_v2agr\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "embeddings = complete_urls.apply(lambda x: get_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0996729, 0.028490392, 0.20510468, 0.5868249...\n",
       "1    [0.086341664, 0.13112758, 0.0015521318, 0.2116...\n",
       "2    [0.10442628, 0.11352078, 0.7367716, 2.401755, ...\n",
       "3    [0.06998727, 3.4273074, 0.0, 2.3481488, 0.0052...\n",
       "4    [0.10927686, 0.12103541, 2.4254398, 0.02788562...\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures[\"complete_url\"] = complete_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures['embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>complete_url</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>105112_b</td>\n",
       "      <td>../slnp_faces_leg_55/105112_b/0.jpg</td>\n",
       "      <td>[0.0996729, 0.028490392, 0.20510468, 0.5868249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0.jpg</td>\n",
       "      <td>105112_b</td>\n",
       "      <td>../slnp_faces_leg_55/105112_b/0_0.jpg</td>\n",
       "      <td>[0.086341664, 0.13112758, 0.0015521318, 0.2116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0.jpg</td>\n",
       "      <td>105112_b</td>\n",
       "      <td>../slnp_faces_leg_55/105112_b/1_0.jpg</td>\n",
       "      <td>[0.10442628, 0.11352078, 0.7367716, 2.401755, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_0.jpg</td>\n",
       "      <td>105112_b</td>\n",
       "      <td>../slnp_faces_leg_55/105112_b/2_0.jpg</td>\n",
       "      <td>[0.06998727, 3.4273074, 0.0, 2.3481488, 0.0052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_0.jpg</td>\n",
       "      <td>105112_b</td>\n",
       "      <td>../slnp_faces_leg_55/105112_b/3_0.jpg</td>\n",
       "      <td>[0.10927686, 0.12103541, 2.4254398, 0.02788562...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file      name                           complete_url  \\\n",
       "0    0.jpg  105112_b    ../slnp_faces_leg_55/105112_b/0.jpg   \n",
       "1  0_0.jpg  105112_b  ../slnp_faces_leg_55/105112_b/0_0.jpg   \n",
       "2  1_0.jpg  105112_b  ../slnp_faces_leg_55/105112_b/1_0.jpg   \n",
       "3  2_0.jpg  105112_b  ../slnp_faces_leg_55/105112_b/2_0.jpg   \n",
       "4  3_0.jpg  105112_b  ../slnp_faces_leg_55/105112_b/3_0.jpg   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.0996729, 0.028490392, 0.20510468, 0.5868249...  \n",
       "1  [0.086341664, 0.13112758, 0.0015521318, 0.2116...  \n",
       "2  [0.10442628, 0.11352078, 0.7367716, 2.401755, ...  \n",
       "3  [0.06998727, 3.4273074, 0.0, 2.3481488, 0.0052...  \n",
       "4  [0.10927686, 0.12103541, 2.4254398, 0.02788562...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pictures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo imagens em que não foi possível extrair os embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paulo\\.virtualenvs\\face_clustering-td_v2agr\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:57: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "invalid = pictures.loc[pictures[\"embeddings\"] == '-'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de imagens invalidas: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de imagens invalidas: \"+str(len(invalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures = pictures.drop(invalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures.to_pickle(f'faces_leg55_embeddings_{backbone}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
